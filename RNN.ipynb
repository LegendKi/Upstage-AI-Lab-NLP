{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN 구현\n",
    "- 이 코드는 간단한 RNN 모델을 정의한다.\n",
    "    - `__init__` 함수에서는 필요한 레이어를 정의하고\n",
    "    - `forward` 함수에서는 이 레이어들을 어떻게 연결할지를 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module): # SimpleRNN 클래스 선언\n",
    "    def __init__(self, input_size, hidden_size, output_size): \n",
    "        super(SimpleRNN, self).__init__() # nn.Module의 초기화 함수 상속\n",
    "        self.M = hidden_size # hidden state의 크기 지정\n",
    "        self.D = input_size # 입력 차원의 크기 지정\n",
    "        self.K = output_size # 출력 차원의 크기 지정\n",
    "        self.rnn = nn.RNN( # RNN 모듈 생성\n",
    "            input_size=self.D, # 입력 차원의 크기\n",
    "            hidden_size=self.M, # hidden state의 크기\n",
    "            nonlinearity='tanh', # 활성화 함수로 tanh 사용\n",
    "            batch_first=True # 첫 번째 차원이 batch size임을 명시\n",
    "        )\n",
    "        self.fc = nn.Linear(self.M, self.K) # 출력을 위한 선형 변환 정의\n",
    "\n",
    "    def forward(self, X): # 순전파 함수 정의\n",
    "        h0 = torch.zeros(1, X.size(0), self.M).to(device) # 초기 hidden state를 0으로 초기화\n",
    "\n",
    "        out, _ = self.rnn(X, h0) # RNN에 입력을 전닳하고 출력과 hidden state를 받음\n",
    "\n",
    "        out = self.fc(out[:, -1, :]) # 마지막 시간 단계의 출력만 사용하여 선형 변환을 수행\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/300], Loss: 0.2563\n",
      "Epoch [60/300], Loss: 0.0810\n",
      "Epoch [90/300], Loss: 0.0424\n",
      "Epoch [120/300], Loss: 0.0282\n",
      "Epoch [150/300], Loss: 0.0208\n",
      "Epoch [180/300], Loss: 0.0163\n",
      "Epoch [210/300], Loss: 0.0132\n",
      "Epoch [240/300], Loss: 0.0110\n",
      "Epoch [270/300], Loss: 0.0093\n",
      "Epoch [300/300], Loss: 0.0081\n"
     ]
    }
   ],
   "source": [
    "model = SimpleRNN(input_size=2, hidden_size=20, output_size=2).to(device) # 모델 생성\n",
    "criterion = nn.CrossEntropyLoss() # 손실 함수 정의\n",
    "optimizer = torch.optim.Adam(model.parameters()) # 옵티마이저 정의\n",
    "\n",
    "# 더미 데이터 생성\n",
    "inputs = torch.from_numpy(np.array([[[1, 2], [3, 4], [5, 6]]], dtype=np.float32)).to(device)\n",
    "\n",
    "for epoch in range(300):\n",
    "    model.zero_grad() # 기울기 초기화\n",
    "    outputs = model(inputs) # 모델 출력 계산\n",
    "    loss = criterion(outputs, torch.tensor([0]).to(device)) # 손실 계산\n",
    "    loss.backward() # 역전파\n",
    "    optimizer.step() # 파라미터 업데이트\n",
    "\n",
    "    if (epoch + 1) % 30 == 0: # 30 에폭마다 손실 출력\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, 300, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module): # LSTM 클래스 선언\n",
    "    def __init__(self, input_size, hidden_size, output_size): \n",
    "        super(LSTM, self).__init__() # nn.Module의 초기화 함수 상속\n",
    "        self.D = input_size # 입력 차원의 크기 지정\n",
    "        self.M = hidden_size # hidden state의 크기 지정\n",
    "        self.K = output_size # 출력 차원의 크기 지정\n",
    "        self.lstm = nn.LSTM( # LSTM 모듈 생성\n",
    "            input_size=self.D, # 입력 차원의 크기\n",
    "            hidden_size=self.M, # hidden state의 크기\n",
    "            batch_first=True # 첫 번째 차원이 batch size임을 명시\n",
    "        )\n",
    "        self.fc = nn.Linear(self.M, self.K) # 출력을 위한 선형 변환 정의\n",
    "\n",
    "    def forward(self, X): # 순전파 함수 정의\n",
    "        h0 = torch.zeros(1, X.size(0), self.M).to(device) # 초기 hidden state를 0으로 초기화\n",
    "        c0 = torch.zeros(1, X.size(0), self.M).to(device) # 초기 cell state를 0으로 초기화\n",
    "\n",
    "        out, _ = self.lstm(X, (h0, c0)) # LSTM에 입력을 전달하고 출력과 hidden state를 받음\n",
    "\n",
    "        out = self.fc(out[:, -1, :]) # 마지막 시간 단계의 출력만 사용하여 선형 변환을 수행\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/300], Loss: 0.4870\n",
      "Epoch [60/300], Loss: 0.1960\n",
      "Epoch [90/300], Loss: 0.0686\n",
      "Epoch [120/300], Loss: 0.0328\n",
      "Epoch [150/300], Loss: 0.0198\n",
      "Epoch [180/300], Loss: 0.0134\n",
      "Epoch [210/300], Loss: 0.0098\n",
      "Epoch [240/300], Loss: 0.0076\n",
      "Epoch [270/300], Loss: 0.0061\n",
      "Epoch [300/300], Loss: 0.0051\n"
     ]
    }
   ],
   "source": [
    "model = LSTM(input_size = 2, hidden_size=20, output_size=2).to(device) # 모델 생성\n",
    "criterion = nn.CrossEntropyLoss() # 손실 함수 정의\n",
    "optimizer = torch.optim.Adam(model.parameters()) # 옵티마이저 정의\n",
    "\n",
    "for epoch in range(300):\n",
    "    model.zero_grad() # 기울기 초기화\n",
    "    outputs = model(inputs) # 모델 출력 계산\n",
    "    loss = criterion(outputs, torch.tensor([1]).to(device)) # 손실 계산\n",
    "    loss.backward() # 역전파\n",
    "    optimizer.step() # 파라미터 업데이트\n",
    "\n",
    "    if (epoch + 1) % 30 == 0: \n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, 300, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module): # GRU 클래스 선언\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRU, self).__init__() # nn.Module의 초기화 함수 상속\n",
    "        self.D = input_size # 입력 차원의 크기 지정\n",
    "        self.M = hidden_size # hidden state의 크기 지정\n",
    "        self.K = output_size # 출력 차원의 크기 지정\n",
    "        self.gru = nn.GRU( # GRU 모듈 생성\n",
    "            input_size=self.D, # 입력 차원의 크기\n",
    "            hidden_size=self.M, # hidden state의 크기\n",
    "            batch_first=True # 첫 번째 차원이 batch size임을 명시\n",
    "        )\n",
    "        self.fc = nn.Linear(self.M, self.K)\n",
    "\n",
    "    def forward(self, X): # 순전파 함수 정의\n",
    "        h0 = torch.zeros(1, X.size(0), self.M).to(device) # 초기 hidden state를 0으로 초기화\n",
    "\n",
    "        out, _ = self.gru(X, h0) # GRU에 입력을 전달하고 출력과 hidden state를 받음\n",
    "\n",
    "        out = self.fc(out[:, -1, :]) # 마지막 시간 단계의 출력만 사용하여 선형 변환을 수행\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/300], Loss: 0.1834\n",
      "Epoch [60/300], Loss: 0.0659\n",
      "Epoch [90/300], Loss: 0.0347\n",
      "Epoch [120/300], Loss: 0.0225\n",
      "Epoch [150/300], Loss: 0.0161\n",
      "Epoch [180/300], Loss: 0.0123\n",
      "Epoch [210/300], Loss: 0.0098\n",
      "Epoch [240/300], Loss: 0.0080\n",
      "Epoch [270/300], Loss: 0.0067\n",
      "Epoch [300/300], Loss: 0.0057\n"
     ]
    }
   ],
   "source": [
    "model = GRU(input_size=2, hidden_size=20, output_size=2).to(device) # 모델 생성\n",
    "criterion = nn.CrossEntropyLoss() # 손실 함수 정의\n",
    "optimizer = torch.optim.Adam(model.parameters()) # 옵티마이저 정의\n",
    "\n",
    "for epoch in range(300):\n",
    "    model.zero_grad() # 기울기 초기화\n",
    "    outputs = model(inputs) # 모델 출력 계산\n",
    "    loss = criterion(outputs, torch.tensor([0]).to(device)) # 손실 계산\n",
    "    loss.backward() # 역전파\n",
    "    optimizer.step() # 파라미터 업데이트\n",
    "\n",
    "    if (epoch + 1) % 30 == 0: \n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, 300, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-to-One RNN\n",
    "이 모델은 각 입력에 대해 하나의 출력을 생성하는 기본적인 RNN 구조로 예를 들어 주어진 숫자의 제곱을 예측하는 문제를 해결할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/4000], Loss: 43.8084\n",
      "Epoch [200/4000], Loss: 22.8585\n",
      "Epoch [300/4000], Loss: 17.2761\n",
      "Epoch [400/4000], Loss: 12.4721\n",
      "Epoch [500/4000], Loss: 7.7927\n",
      "Epoch [600/4000], Loss: 4.5822\n",
      "Epoch [700/4000], Loss: 3.0815\n",
      "Epoch [800/4000], Loss: 2.5274\n",
      "Epoch [900/4000], Loss: 2.2812\n",
      "Epoch [1000/4000], Loss: 2.1124\n",
      "Epoch [1100/4000], Loss: 1.9652\n",
      "Epoch [1200/4000], Loss: 1.8250\n",
      "Epoch [1300/4000], Loss: 1.6867\n",
      "Epoch [1400/4000], Loss: 1.5481\n",
      "Epoch [1500/4000], Loss: 1.4085\n",
      "Epoch [1600/4000], Loss: 1.2680\n",
      "Epoch [1700/4000], Loss: 1.1277\n",
      "Epoch [1800/4000], Loss: 0.9892\n",
      "Epoch [1900/4000], Loss: 0.8546\n",
      "Epoch [2000/4000], Loss: 0.7261\n",
      "Epoch [2100/4000], Loss: 0.6059\n",
      "Epoch [2200/4000], Loss: 0.4960\n",
      "Epoch [2300/4000], Loss: 0.3979\n",
      "Epoch [2400/4000], Loss: 0.3124\n",
      "Epoch [2500/4000], Loss: 0.2399\n",
      "Epoch [2600/4000], Loss: 0.1800\n",
      "Epoch [2700/4000], Loss: 0.1318\n",
      "Epoch [2800/4000], Loss: 0.0941\n",
      "Epoch [2900/4000], Loss: 0.0655\n",
      "Epoch [3000/4000], Loss: 0.0444\n",
      "Epoch [3100/4000], Loss: 0.0293\n",
      "Epoch [3200/4000], Loss: 0.0188\n",
      "Epoch [3300/4000], Loss: 0.0117\n",
      "Epoch [3400/4000], Loss: 0.0071\n",
      "Epoch [3500/4000], Loss: 0.0042\n",
      "Epoch [3600/4000], Loss: 0.0024\n",
      "Epoch [3700/4000], Loss: 0.0013\n",
      "Epoch [3800/4000], Loss: 0.0007\n",
      "Epoch [3900/4000], Loss: 0.0004\n",
      "Epoch [4000/4000], Loss: 0.0002\n",
      "Input: 2.0, Output: 4.013523578643799, 정답: 4.0\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randint(1, 5, size=(1000, 1, 1)) # 입력 데이터 생성, 1~4 사이의 정수 1000개를 랜덤하게 선택\n",
    "Y = np.square(X) # 출력 데이터 생성, 입력에 대한 제곱을 계산\n",
    "\n",
    "X = torch.from_numpy(X.astype(np.float32)).to(device) # 입력 데이터를 텐서로 변환\n",
    "Y = torch.from_numpy(Y.astype(np.float32)).squeeze(-1).to(device) # 출력 데이터를 텐서로 변환\n",
    "\n",
    "model = SimpleRNN(input_size=1, hidden_size=40, output_size=1).to(device) # 모델 생성\n",
    "criterion = nn.MSELoss() # 손실 함수 정의\n",
    "optimizer = torch.optim.Adam(model.parameters()) # 옵티마이저 정의\n",
    "\n",
    "for epoch in range(4000):\n",
    "    model.zero_grad() # 기울기 초기화\n",
    "    outputs = model(X) # 모델 출력 계산\n",
    "    loss = criterion(outputs, Y) # 손실 계산\n",
    "    loss.backward() # 역전파\n",
    "    optimizer.step() # 파라미터 업데이트\n",
    "\n",
    "    if (epoch + 1) % 100 == 0: \n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, 4000, loss.item()))\n",
    "\n",
    "# Infenrence\n",
    "X_test = torch.tensor([[[2.0]]], dtype=torch.float32).to(device) # 테스트 데이터 생성\n",
    "print(f\"Input: 2.0, Output: {model(X_test).item()}, 정답: {np.square(2.0)}\") # 예측값 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-to-Many\n",
    "One-to-Many 구조의 모델은 하나의 입력에 대해 여러 개의 출력을 생성하는 구조이다. 예를 들어 주어진 수자의 배수를 예측하는 문제를 해결할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/4000], Loss: 224.2033\n",
      "Epoch [200/4000], Loss: 130.7445\n",
      "Epoch [300/4000], Loss: 79.7772\n",
      "Epoch [400/4000], Loss: 55.0492\n",
      "Epoch [500/4000], Loss: 42.4101\n",
      "Epoch [600/4000], Loss: 34.5626\n",
      "Epoch [700/4000], Loss: 28.0176\n",
      "Epoch [800/4000], Loss: 21.6280\n",
      "Epoch [900/4000], Loss: 15.8146\n",
      "Epoch [1000/4000], Loss: 11.1943\n",
      "Epoch [1100/4000], Loss: 7.9706\n",
      "Epoch [1200/4000], Loss: 5.9303\n",
      "Epoch [1300/4000], Loss: 4.6914\n",
      "Epoch [1400/4000], Loss: 3.9157\n",
      "Epoch [1500/4000], Loss: 3.3828\n",
      "Epoch [1600/4000], Loss: 2.9746\n",
      "Epoch [1700/4000], Loss: 2.6361\n",
      "Epoch [1800/4000], Loss: 2.3415\n",
      "Epoch [1900/4000], Loss: 2.0778\n",
      "Epoch [2000/4000], Loss: 1.8374\n",
      "Epoch [2100/4000], Loss: 1.6162\n",
      "Epoch [2200/4000], Loss: 1.4117\n",
      "Epoch [2300/4000], Loss: 1.2228\n",
      "Epoch [2400/4000], Loss: 1.0491\n",
      "Epoch [2500/4000], Loss: 0.8906\n",
      "Epoch [2600/4000], Loss: 0.7475\n",
      "Epoch [2700/4000], Loss: 0.6202\n",
      "Epoch [2800/4000], Loss: 0.5085\n",
      "Epoch [2900/4000], Loss: 0.4121\n",
      "Epoch [3000/4000], Loss: 0.3303\n",
      "Epoch [3100/4000], Loss: 0.2622\n",
      "Epoch [3200/4000], Loss: 0.2065\n",
      "Epoch [3300/4000], Loss: 0.1617\n",
      "Epoch [3400/4000], Loss: 0.1263\n",
      "Epoch [3500/4000], Loss: 0.0987\n",
      "Epoch [3600/4000], Loss: 0.0775\n",
      "Epoch [3700/4000], Loss: 0.0614\n",
      "Epoch [3800/4000], Loss: 0.0492\n",
      "Epoch [3900/4000], Loss: 0.0400\n",
      "Epoch [4000/4000], Loss: 0.0329\n",
      "-------------------- 추론 결과 --------------------\n",
      "Input: 2.0\n",
      "Output: 2.0, 정답: 2\n",
      "Output: 3.9, 정답: 4\n",
      "Output: 5.9, 정답: 6\n",
      "Output: 7.9, 정답: 8\n",
      "Output: 9.9, 정답: 10\n",
      "Output: 11.9, 정답: 12\n",
      "Output: 13.9, 정답: 14\n",
      "Output: 15.9, 정답: 16\n",
      "Output: 17.9, 정답: 18\n",
      "Output: 19.9, 정답: 20\n"
     ]
    }
   ],
   "source": [
    "# 입력의 배수 10개를 타겟으로 설정\n",
    "# 아래의 One-to-Many는 하나의 숫자 입력 데이터를 받고 입력 데이터의 배수 10개를 출력하는 RNN 모델\n",
    "\n",
    "class SimpleRNNOne2Many(nn.Module): # One-to-Many RNN 클래스 선언\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleRNNOne2Many, self).__init__()\n",
    "        self.D = input_size\n",
    "        self.M = hidden_size\n",
    "        self.K = output_size\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=self.D,\n",
    "            hidden_size=self.M,\n",
    "            nonlinearity='tanh',\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(self.M, self.K) \n",
    "    \n",
    "    def forward(self, X): # 순전파 함수 정의\n",
    "        h0 = torch.zeros(1, X.size(0), self.M).to(device) # 초기 hidden state를 0으로 초기화\n",
    "        out, _ = self.rnn(X, h0) # RNN에 입력을 전달하고 출력과 hidden state를 받음\n",
    "        out = self.fc(out) # 선형 변환을 수행\n",
    "        return out.view(-1, 10)\n",
    "    \n",
    "X = np.random.randint(1, 5, size=(1000, 1, 1)) # 입력 데이터 생성\n",
    "Y = np.array([[i*j for i in range(1, 11)] for j in X.squeeze()]) # 출력 데이터 생성\n",
    "\n",
    "X = torch.from_numpy(X.astype(np.float32)).to(device) # 입력 데이터를 텐서로 변환\n",
    "Y = torch.from_numpy(Y.astype(np.float32)).to(device) # 출력 데이터를 텐서로 변환\n",
    "\n",
    "model = SimpleRNNOne2Many(input_size=1, hidden_size=40, output_size=10).to(device) # 모델 생성\n",
    "criterion = nn.MSELoss() # 손실 함수 정의\n",
    "optimizer = torch.optim.Adam(model.parameters()) # 옵티마이저 정의\n",
    "\n",
    "for epoch in range(4000):\n",
    "    model.zero_grad() # 기울기 초기화\n",
    "    outputs = model(X) # 모델 출력 계산\n",
    "    loss = criterion(outputs, Y) # 손실 계산\n",
    "    loss.backward() # 역전파\n",
    "    optimizer.step() # 파라미터 업데이트\n",
    "\n",
    "    if (epoch + 1) % 100 == 0: \n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, 4000, loss.item()))\n",
    "\n",
    "# Inference\n",
    "X_test = torch.tensor([[[2.0]]], dtype=torch.float32).to(device) # 테스트 데이터 생성\n",
    "print('-' * 20, '추론 결과', '-' * 20)\n",
    "print(f\"Input: 2.0\")\n",
    "output = [round(num, 1) for num in model(X_test).squeeze().tolist()] # 테스트 데이터에 대한 예측값 계산\n",
    "answer = list(range(2, 21, 2)) # 정답 리스트 생성\n",
    "\n",
    "for o, a in zip(output, answer): # 예측값과 정답을 비교하여 출력\n",
    "    print(f\"Output: {o}, 정답: {a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many-to-One\n",
    "Many-to-One 구조의 모델은 여러개의 입력에 대해 하나의 출력을 생성한다. 예를 들어 주어진 숫자 리스트의 합을 예측하는 문제를 해결할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/4000], Loss: 1517.0813\n",
      "Epoch [200/4000], Loss: 1144.5833\n",
      "Epoch [300/4000], Loss: 866.0313\n",
      "Epoch [400/4000], Loss: 652.1705\n",
      "Epoch [500/4000], Loss: 489.3702\n",
      "Epoch [600/4000], Loss: 367.6650\n",
      "Epoch [700/4000], Loss: 278.7727\n",
      "Epoch [800/4000], Loss: 215.5821\n",
      "Epoch [900/4000], Loss: 172.0082\n",
      "Epoch [1000/4000], Loss: 142.9507\n",
      "Epoch [1100/4000], Loss: 124.2650\n",
      "Epoch [1200/4000], Loss: 112.7084\n",
      "Epoch [1300/4000], Loss: 105.8512\n",
      "Epoch [1400/4000], Loss: 101.9564\n",
      "Epoch [1500/4000], Loss: 99.8430\n",
      "Epoch [1600/4000], Loss: 98.7491\n",
      "Epoch [1700/4000], Loss: 98.2091\n",
      "Epoch [1800/4000], Loss: 97.9534\n",
      "Epoch [1900/4000], Loss: 97.8331\n",
      "Epoch [2000/4000], Loss: 97.7624\n",
      "Epoch [2100/4000], Loss: 93.7729\n",
      "Epoch [2200/4000], Loss: 57.0565\n",
      "Epoch [2300/4000], Loss: 34.1876\n",
      "Epoch [2400/4000], Loss: 24.8786\n",
      "Epoch [2500/4000], Loss: 19.2039\n",
      "Epoch [2600/4000], Loss: 15.3059\n",
      "Epoch [2700/4000], Loss: 12.4426\n",
      "Epoch [2800/4000], Loss: 10.2776\n",
      "Epoch [2900/4000], Loss: 8.5976\n",
      "Epoch [3000/4000], Loss: 7.2794\n",
      "Epoch [3100/4000], Loss: 6.2149\n",
      "Epoch [3200/4000], Loss: 5.3585\n",
      "Epoch [3300/4000], Loss: 4.6492\n",
      "Epoch [3400/4000], Loss: 4.0938\n",
      "Epoch [3500/4000], Loss: 3.5719\n",
      "Epoch [3600/4000], Loss: 3.1564\n",
      "Epoch [3700/4000], Loss: 2.8032\n",
      "Epoch [3800/4000], Loss: 2.4988\n",
      "Epoch [3900/4000], Loss: 2.2534\n",
      "Epoch [4000/4000], Loss: 2.0084\n",
      "-------------------- 추론 결과 --------------------\n",
      "Input: [2.0, 4.0, 6.0, 8.0, 10.0, 11.0]\n",
      "Output: 40.9, 정답: 41.0\n"
     ]
    }
   ],
   "source": [
    "# 아래의 Many-to-One은 여러 개의 숫자 입력 데이터를 받고 입력된 데이터의 총 합을 예측하는 RNN 모델\n",
    "\n",
    "class ManyToOneRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ManyToOneRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True) # RNN 모듈 생성\n",
    "        self.fc = nn.Linear(hidden_size, output_size) # 출력을 위한 선형 변환 정의\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device) # 초기 hidden state를 0으로 초기화\n",
    "        out, _ = self.rnn(x, h0) # RNN에 입력을 전달하고 출력과 hidden state를 받음\n",
    "        out = self.fc(out[:, -1, :]) # 마지막 시간 단계의 출력만 사용하여 선형 변환을 수행\n",
    "\n",
    "        return out\n",
    "    \n",
    "X = np.random.randint(1, 15, size=(50000, 6, 1)) # 입력 데이터 생성\n",
    "Y = np.array([np.sum(x) for x in X]) # 출력 데이터 생성\n",
    "\n",
    "X = torch.from_numpy(X.astype(np.float32)).to(device) # 입력 데이터를 텐서로 변환\n",
    "Y = torch.from_numpy(Y.astype(np.float32)).to(device) # 출력 데이터를 텐서로 변환\n",
    "\n",
    "model = ManyToOneRNN(input_size=1, hidden_size=50, output_size=1).to(device) # 모델 생성\n",
    "criterion = nn.MSELoss() # 손실 함수 정의\n",
    "optimizer = torch.optim.Adam(model.parameters()) # 옵티마이저 정의\n",
    "\n",
    "for epoch in range(4000):\n",
    "    model.zero_grad() # 기울기 초기화\n",
    "    outputs = model(X) # 모델 출력 계산\n",
    "    loss = criterion(outputs.squeeze(), Y) # 손실 계산\n",
    "    loss.backward() # 역전파\n",
    "    optimizer.step() # 파라미터 업데이트\n",
    "\n",
    "    if (epoch + 1) % 100 == 0: \n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, 4000, loss.item()))\n",
    "\n",
    "# Inference\n",
    "X_test = torch.tensor([[[2.0], [4.0], [6.0], [8.0], [10.0], [11.0]]], dtype=torch.float32).to(device) # 테스트 데이터 생성\n",
    "print('-' * 20, '추론 결과', '-' * 20)\n",
    "print(f\"Input: {X_test.squeeze().tolist()}\")\n",
    "output = round(model(X_test).item(), 1)\n",
    "answer = round(sum(X_test.squeeze().tolist()), 1)\n",
    "\n",
    "print(f\"Output: {output}, 정답: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many-to-Many RNN\n",
    "Many-to-Many 구조의 모델은 여러 개의 입력에 대해 여러 개의 출력을 생성한다. 예를 들어 주어진 숫자 리스트의 누적 합을 예측하는 문제를 해결할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/4000], Loss: 1953.6315\n",
      "Epoch [200/4000], Loss: 1548.8319\n",
      "Epoch [300/4000], Loss: 1250.9359\n",
      "Epoch [400/4000], Loss: 1019.4675\n",
      "Epoch [500/4000], Loss: 837.5214\n",
      "Epoch [600/4000], Loss: 690.1598\n",
      "Epoch [700/4000], Loss: 567.5901\n",
      "Epoch [800/4000], Loss: 469.3835\n",
      "Epoch [900/4000], Loss: 390.6965\n",
      "Epoch [1000/4000], Loss: 327.0983\n",
      "Epoch [1100/4000], Loss: 275.5186\n",
      "Epoch [1200/4000], Loss: 233.3695\n",
      "Epoch [1300/4000], Loss: 198.6822\n",
      "Epoch [1400/4000], Loss: 169.9465\n",
      "Epoch [1500/4000], Loss: 146.0302\n",
      "Epoch [1600/4000], Loss: 126.0160\n",
      "Epoch [1700/4000], Loss: 109.1813\n",
      "Epoch [1800/4000], Loss: 94.9762\n",
      "Epoch [1900/4000], Loss: 82.9228\n",
      "Epoch [2000/4000], Loss: 72.6546\n",
      "Epoch [2100/4000], Loss: 63.8635\n",
      "Epoch [2200/4000], Loss: 56.3131\n",
      "Epoch [2300/4000], Loss: 49.8050\n",
      "Epoch [2400/4000], Loss: 44.1751\n",
      "Epoch [2500/4000], Loss: 39.2975\n",
      "Epoch [2600/4000], Loss: 35.0264\n",
      "Epoch [2700/4000], Loss: 31.3073\n",
      "Epoch [2800/4000], Loss: 28.1150\n",
      "Epoch [2900/4000], Loss: 25.1898\n",
      "Epoch [3000/4000], Loss: 22.6701\n",
      "Epoch [3100/4000], Loss: 20.4328\n",
      "Epoch [3200/4000], Loss: 18.4482\n",
      "Epoch [3300/4000], Loss: 16.6795\n",
      "Epoch [3400/4000], Loss: 15.1015\n",
      "Epoch [3500/4000], Loss: 13.6905\n",
      "Epoch [3600/4000], Loss: 12.4279\n",
      "Epoch [3700/4000], Loss: 11.2954\n",
      "Epoch [3800/4000], Loss: 10.2789\n",
      "Epoch [3900/4000], Loss: 9.3637\n",
      "Epoch [4000/4000], Loss: 8.5420\n",
      "-------------------- 추론 결과 --------------------\n",
      "Input: [10, 11, 12, 13, 14]\n",
      "Output: 9.9, 정답: 10\n",
      "Output: 21.0, 정답: 21\n",
      "Output: 33.0, 정답: 33\n",
      "Output: 46.1, 정답: 46\n",
      "Output: 60.3, 정답: 60\n"
     ]
    }
   ],
   "source": [
    "# 입력 데이터 리스트의 누적 합 리스트가 정답\n",
    "# 아래의 Many-to-Many 구조는 여러 개의 숫자 입력 데이터를 받고 입력 데이터의 누적합을 예측하는 RNN 모델\n",
    "\n",
    "class ManyToManyRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ManyToManyRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True) # RNN 모듈 생성\n",
    "        self.fc = nn.Linear(hidden_size, output_size) # 출력을 위한 선형 변환 정의\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device) # 초기 hidden state를 0으로 초기화\n",
    "        out, _ = self.rnn(x, h0) # RNN에 입력을 전달하고 출력과 hidden state를 받음\n",
    "        out = self.fc(out) # 선형 변환을 수행\n",
    "\n",
    "        return out\n",
    "    \n",
    "X = np.array([[[np.random.randint(0, 31)] for _ in range(5)] for _ in range(3000)])\n",
    "Y = np.array([np.cumsum(x) for x in X]) \n",
    "\n",
    "X = torch.from_numpy(X.astype(np.float32)) # 입력 데이터를 텐서로 변환\n",
    "Y = torch.from_numpy(Y.astype(np.float32)) # 출력 데이터를 텐서로 변환\n",
    "\n",
    "model = ManyToManyRNN(1, 60, 1)\n",
    "criterion = nn.MSELoss() # 손실 함수 정의\n",
    "optimizer = torch.optim.Adam(model.parameters()) # 옵티마이저 정의\n",
    "\n",
    "for epoch in range(4000):\n",
    "    model.zero_grad() # 기울기 초기화\n",
    "    outputs = model(X) # 모델 출력 계산\n",
    "    loss = criterion(outputs.squeeze(), Y) # 손실 계산\n",
    "    loss.backward() # 역전파\n",
    "    optimizer.step() # 파라미터 업데이트\n",
    "\n",
    "    if (epoch + 1) % 100 == 0: \n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, 4000, loss.item()))\n",
    "\n",
    "# Inference\n",
    "X_test = torch.tensor([[[i+10] for i in range(5)]], dtype=torch.float32) # 테스트 데이터 생성\n",
    "print('-' * 20, '추론 결과', '-' * 20)\n",
    "print(f\"Input: {list(range(10, 15))}\")\n",
    "output = [round(num, 1) for num in model(X_test).squeeze().tolist()] # 모델의 출력 계산\n",
    "answer = list(np.cumsum(range(10, 15))) # 정답 계산\n",
    "\n",
    "for o, a in zip(output, answer): # 모델의 출력과 정답 비교\n",
    "    print(f\"Output: {o}, 정답: {a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
