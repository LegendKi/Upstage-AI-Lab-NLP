{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역 데이터셋 다운로드\n",
    "!echo \"download machine translation dataset from http://www.manythings.org/anki/...\"\n",
    "\n",
    "!curl -o \"fra-eng.zip\" \"http://www.manythings.org/anki/fra-eng.zip\"\n",
    "\n",
    "!unzip './fra-eng.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, OrderedDict\n",
    "import nltk\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "from torch.nn.utils.rnn import PackedSequence,pack_padded_sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "random.seed(7)\n",
    "%matplotlib inline\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 설정\n",
    "USE_CUDA = torch.cuda.is_available() # 현재 환경에서 CUDA를 사용할 수 있는지 확인\n",
    "\n",
    "# CUDA를 사용할 수 있으면 CUDA tensor를, 그렇지 않으면 CPU tensor를 사용\n",
    "FloatTensor = torch.cuda.FloatTensor if USE_CUDA else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if USE_CUDA else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if USE_CUDA else torch.ByteTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2seq with Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getBatch 함수 구현\n",
    "`getBatch` 함수는 주어진 `train_data`에서 무작위로 선택된 배치를 생성하는 역할을 한다. \n",
    "- `train_data`를 무작위로 섞는다.\n",
    "- `sindex`와 `eindex` 변수를 사용하여 `train_data`에서 배치를 추출한다.\n",
    "- `eindex`를 `batch_size`만큼 증가시키고 `sindex`를 이전 `eindex` 값으로 업데이트한다.\n",
    "- `eindex`가 `train_data`의 길이보다 작은 동안 위 과정을 반복하여 배치를 생성한다.\n",
    "- `eindex`가 `train_data`의 길이보다 크거나 같아지면 남은 데이터를 마지막 배치로 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBatch(batch_size, train_data):\n",
    "    random.shuffle(train_data) # 데이터를 무작위로 섞는다.\n",
    "    sindex = 0 # 시작 인덱스\n",
    "    eindex = batch_size # 종료 인덱스\n",
    "    while eindex < len(train_data): \n",
    "        batch = train_data[sindex:eindex] # batch_size만큼 데이터를 불러온다.\n",
    "        temp = eindex # 현재 인덱스를 저장\n",
    "        eindex = eindex + batch_size # eindex를 배치 사이즈만큼 증가\n",
    "        sindex = temp # sindex를 이전 eindex값으로 변경\n",
    "        yield batch # batch를 반환\n",
    "\n",
    "    if eindex >= len(train_data): \n",
    "        batch = train_data[sindex:] # 남은 데이터를 배치로 만든다.\n",
    "        yield batch # batch를 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pad_to_batch 함수 구현\n",
    "`pad_to_batch` 함수는 주어진 배치에 패딩을 적용핳여 입력 시퀀스와 타겟 시퀀스를 동일한 길이로 만든다. \n",
    "- 배치를 길이에 따라 정렬\n",
    "- 입력 시퀀스와 타겟 시퀀스의 길이를 계산\n",
    "- 각 시퀀스에 패딩을 적용하여 동일한 길이로 변환\n",
    "- 입력 변수와 타겟 변수를 생성하고 각 시퀀스의 실제 길이를 계산\n",
    "- 입력 변수, 타겟 변수, 입력 길이, 타겟 길이를 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_batch(batch, x_to_ix, y_to_ix):\n",
    "    sorted_batch = sorted(batch, key=lambda b:b[0].size(1), reverse=True) # batch를 길이에 따라 내림차순으로 정렬\n",
    "    x,y = list(zip(*sorted_batch)) # x와 y를 분리\n",
    "    max_x = max([s.size(1) for s in x]) # 입력 데이터 최대 길이\n",
    "    max_y = max([s.size(1) for s in y]) # 타겟 데이터 최대 길이\n",
    "    x_p, y_p = [], [] # 패딩을 적용할 입력, 타겟 리스트\n",
    "\n",
    "    for i in range(len(batch)):\n",
    "        if x[i].size(1) < max_x: # 현재 데이터가 최대 길이보다 짧다면\n",
    "            # 패딩을 적용하여 최대 길이로 만든다.\n",
    "            x_p.append(torch.cat([x[i], Variable(LongTensor([x_to_ix['<PAD>']] * (max_x - x[i].size(1))).view(1, -1))], 1))\n",
    "        else:\n",
    "            x_p.append(x[i]) # 그렇지 않으면 그대로 사용\n",
    "        if y[i].size(1) < max_y: # 타겟 데이터가 최대 길이보다 짧다면\n",
    "            # 패딩을 적용하여 최대 길이로 만든다.\n",
    "            y_p.append(torch.cat([y[i], Variable(LongTensor([y_to_ix['<PAD>']] * (max_y - y[i].size(1))).view(1, -1))], 1))\n",
    "        else:\n",
    "            y_p.append(y[i]) # 그렇지 않으면 그대로 사용\n",
    "\n",
    "    input_var = torch.cat(x_p) # 입력 데이터를 하나의 텐서로 만든다.\n",
    "    target_var = torch.cat(y_p) # 타겟 데이터를 하나의 텐서로 만든다.\n",
    "    input_len = [list(map(lambda s: s ==0, t.data)).count(False) for t in input_var] # 입력 데이터의 각 문장의 실제 길이\n",
    "    target_len = [list(map(lambda s: s ==0, t.data)).count(False) for t in target_var] # 타겟 데이터의 각 문장의 실제 길이\n",
    "\n",
    "    return input_var, target_var, input_len, target_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 load 및 preprocess 코드 구현\n",
    "이 코드에서는 문자열을 처리하고 정규화 하는 두가지 함수를 구현한다.\n",
    "- `unicode_to_ascii` 함수는 유니코드 문자열을 ASCII 문자열로 변환한다. 주어진 유니코드 문자열에서 각 문자를 순회하며 해당 문자가 비수치형인 경우에만 ASCII 문자열에 추가한다.\n",
    "\n",
    "- `normalize_string` 함수는 문자열을 소문자로 변환하고 공백을 제거하며 영문자와 구두점 이외의 문자를 제거한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유니코드 문자열을 ASCII 문자열로 변환\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# 문자열 정규화\n",
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = open('../fra.txt', 'r', encoding='utf-8').readlines()\n",
    "\n",
    "corpus = corpus[:30000]\n",
    "\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리 및 필터링\n",
    "기계 번역을 위한 데이터 전처리와 필터링을 수행한다.\n",
    "최소 및 최대 길이를 설정하여 너무 짧거나 너무 긴 문장을 제외\n",
    "- `MIN_LENGTH` : 문장의 최소 길이를 지정한다.\n",
    "- `MAX_LENGTH` : 문장의 최대 길이를 지정한다.\n",
    "빈 리스트 `X_r`, `y_r`을 생성한 뒤 각각 source와 target 문장을 저장\n",
    "\n",
    "`corpus`의 각 문장에 대해 다음 작업을 수행\n",
    "1. source와 target을 분리 (\\t)으로 구분\n",
    "2. source와 target이 비어있지 않은지 확인하고 비어있다면 해당 문장 건너 뜀\n",
    "3. source와 target을 정규화 하고 공백을 분리한다.\n",
    "4. source와 target의 길이가 최소 및 최대 길이 사이에 있는지 확인하고 `X_r`, `y_r`에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29444 29444\n",
      "['i', 'see', '.'] ['je', 'comprends', '.']\n"
     ]
    }
   ],
   "source": [
    "MIN_LENTH = 3\n",
    "MAX_LENGTH = 25\n",
    "\n",
    "X_r, y_r = [], [] # row 데이터를 저장할 리스트\n",
    "\n",
    "for parallel in corpus:\n",
    "    so, ta, _ = parallel.split('\\t') # 소스와 타겟을 분리\n",
    "    if so.strip() == \"\" or ta.strip() == \"\": # 빈 문자열이라면 건너뛴다.\n",
    "        continue\n",
    "    \n",
    "    normalized_so = normalize_string(so).split() # 소스 문장 정규화\n",
    "    normalized_ta = normalize_string(ta).split() # 타겟 문장 정규화\n",
    "\n",
    "    # 소스 문장과 타겟 문장의 길이가 최소 길이와 최대 길이 사이에 있으면 리스트에 추가\n",
    "    if len(normalized_so) >= MIN_LENTH and len(normalized_so) <= MAX_LENGTH \\\n",
    "    and len(normalized_ta) >= MIN_LENTH and len(normalized_ta) <= MAX_LENGTH:\n",
    "        X_r.append(normalized_so)\n",
    "        y_r.append(normalized_ta)\n",
    "\n",
    "print(len(X_r), len(y_r)) # 소스 문장과 타겟 문장의 개수 출력\n",
    "print(X_r[0], y_r[0]) # 첫 번째 소스 문장과 타겟 문장 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 소스, 타겟 단어장 생성\n",
    "\n",
    "소스와 타겟 데이터를 사용하여 각각의 단어 기반 단어장을 생성한다. 소스와 타겟 데이터를 flatten한 후 중복된 단어를 제거하기 위해 `set()`함수를 사용한다. 이렇게 생성된 단어장은 각각 `source_vocab`과 `targe_vocab`에 저장된다.\n",
    "\n",
    "### 인덱스 매핑 생성\n",
    "단어장을 기반으로 단어와 인덱스 사이의 매핑을 생성한다. `<PAD>`, `<UNK>`, `<s>`, `<\\s>`와 같은 특수 토큰을 포함한 초기 매핑 딕셔너리를 생성한다.\n",
    "`source2index`와 `target2index` 딕셔너리에 각각 소스와 타겟 단어장의 단어들을 추가한다. 인덱스와 단어 사이의 역매핑을 구성하여 추후 데이터 전처리 및 결과 해석에 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4268 7409\n"
     ]
    }
   ],
   "source": [
    "# 소스와 타겟 단어장 생성\n",
    "source_vocab = list(set(flatten(X_r))) # 소스 단어장\n",
    "target_vocab = list(set(flatten(y_r))) # 타겟 단어장\n",
    "print(len(source_vocab), len(target_vocab)) # 소스와 타겟 단어장의 크기 출력\n",
    "\n",
    "source2index = {'<PAD>': 0, '<UNK>': 1, '<s>': 2, '</s>': 3} # 소스 단어장을 인덱스로 변환하는 딕셔너리 초기화\n",
    "for vo in source_vocab:\n",
    "    if source2index.get(vo) is None: # 단어장에 없는 단어라면\n",
    "        source2index[vo] = len(source2index) # 단어를 단어장에 추가\n",
    "index2source = {v:k for k, v in source2index.items()} # 인덱스를 단어로 변환하는 딕셔너리\n",
    "\n",
    "target2index = {'<PAD>': 0, '<UNK>': 1, '<s>': 2, '</s>': 3} # 타겟 단어장을 인덱스로 변환하는 딕셔너리 초기화\n",
    "for vo in target_vocab:\n",
    "    if target2index.get(vo) is None: # 단어장에 없는 단어라면\n",
    "        target2index[vo] = len(target2index) # 단어를 단어장에 추가\n",
    "index2target = {v:k for k, v in target2index.items()} # 인덱스를 단어로 변환하는 딕셔너리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare_sequence 함수와 데이터 전처리\n",
    "- prepare_sequence 함수는 주어진 시퀀스를 인덱스로 변홚하는 함수로 seq와 to_index를 입력으로 받아 시퀀스의 각 단어를 인덱스로 변환하고 Variable로 변환하여 반환한다. 만약 단어가 to_index 딕셔너리에 없으면 unknown 토큰의 인덱스로 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[3844, 2176, 3081,    3]], device='cuda:0'),\n",
       "  tensor([[5610, 4640, 3169,    3]], device='cuda:0')),\n",
       " (tensor([[3844, 3007, 3081,    3]], device='cuda:0'),\n",
       "  tensor([[1744, 2019, 3169,    3]], device='cuda:0')),\n",
       " (tensor([[3844,  801, 1936,    3]], device='cuda:0'),\n",
       "  tensor([[1744, 7071, 1081, 4546,    3]], device='cuda:0')),\n",
       " (tensor([[3844,  801, 1936,    3]], device='cuda:0'),\n",
       "  tensor([[5610, 4268, 7071,  114, 4546,    3]], device='cuda:0')),\n",
       " (tensor([[3844,  801, 3081,    3]], device='cuda:0'),\n",
       "  tensor([[1744, 7071, 1081, 3169,    3]], device='cuda:0'))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_sequence(seq, to_index):\n",
    "    idxs = list(map(lambda w: to_index[w] if to_index.get(w) is not None else to_index['<UNK>'], seq))\n",
    "    return Variable(LongTensor(idxs)) # 변환된 인덱스를 텐서로 벼노한\n",
    "\n",
    "X_p, y_p = [], [] # 인덱스로 변환된 소스와 타겟 데이터를 저장할 리스트\n",
    "\n",
    "for so, ta in zip(X_r, y_r):\n",
    "    X_p.append(prepare_sequence(so + ['</s>'], source2index).view(1, -1)) # 소스 데이터를 인덱스로 변환하여 리스트에 추가\n",
    "    y_p.append(prepare_sequence(ta + ['</s>'], target2index).view(1, -1)) # 타겟 데이터를 인덱스로 변환하여 리스트에 추가\n",
    "\n",
    "train_data = list(zip(X_p, y_p)) # 소스와 타겟 데이터를 묶어 리스트로 만든다.\n",
    "\n",
    "train_data[:5] # 변환된 소스와 타겟 데이터 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, n_layers=1, bidirec=False):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.input_size = input_size \n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # 임베딩 레이어 정의\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "\n",
    "        # 양방향 GRU를 사용할 것인지 여부에 따라 n_direction 설정 (양방향일 경우 2, 단방향일 경우 1)\n",
    "        if bidirec:\n",
    "            self.n_direction = 2\n",
    "            self.gru = nn.GRU(embedding_size, hidden_size, n_layers, batch_first=True, bidirectional=True)\n",
    "        else:\n",
    "            self.n_direction = 1\n",
    "            self.gru = nn.GRU(embedding_size, hidden_size, n_layers, batch_first=True)\n",
    "\n",
    "    # hidden state 초기화\n",
    "    def init_hidden(self, inputs):\n",
    "        hidden = Variable(torch.zeros(self.n_layers * self.n_direction, inputs.size(0), self.hidden_size))\n",
    "        return hidden.cuda() if USE_CUDA else hidden\n",
    "    \n",
    "    # 임베딩 레이어와 GRU 레이어의 가중치를 xavier_uniform 방식으로 초기화\n",
    "    def init_weight(self):\n",
    "        self.embedding.weight = nn.init.xavier_uniform(self.embedding.weight)\n",
    "        self.gru.weight_hh_l0 = nn.init.xavier_uniform(self.gru.weight_hh_l0)\n",
    "        self.gru.weight_ih_l0 = nn.init.xavier_uniform(self.gru.weight_ih_l0)\n",
    "\n",
    "    # 순전파 정의\n",
    "    def forward(self, inputs, input_lengths):\n",
    "        hidden = self.init_hidden(inputs)\n",
    "\n",
    "        embedded = self.embedding(inputs)\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths, batch_first=True)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "\n",
    "        # 레이어 수가 1보다 크면, 마지막 두 레이어의 은닉 상태를 사용하고, 그렇지 않으면 마지막 레이어의 은닉 상태를 사용\n",
    "        if self.n_layers > 1:\n",
    "            if self.n_direction == 2:\n",
    "                hidden = hidden[-2:]\n",
    "            else:\n",
    "                hidden = hidden[-1]\n",
    "\n",
    "        return outputs, torch.cat([h for h in hidden], 1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 7, 1024])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "EMBEDDING_SIZE = 300\n",
    "HIDDEN_SIZE = 512\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_size=len(source2index),\n",
    "    embedding_size=EMBEDDING_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    n_layers=3,\n",
    "    bidirec=True\n",
    ").cuda()\n",
    "\n",
    "encoder.init_weight() # 가중치 초기화\n",
    "\n",
    "ex = next(iter(getBatch(BATCH_SIZE, train_data))) # 미니배치 데이터를 가져온다.\n",
    "inputs, targets, input_lengths, target_lengths = pad_to_batch(ex, source2index, target2index)\n",
    "\n",
    "output, hidden_c = encoder(\n",
    "    inputs=inputs,\n",
    "    input_lengths=input_lengths\n",
    ")\n",
    "\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, n_layers=1, dropout_p=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.gru = nn.GRU(embedding_size + hidden_size, hidden_size, n_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size * 2, input_size)\n",
    "        self.attn = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def init_hidden(self, inputs):\n",
    "        hidden = Variable(torch.zeros(self.n_layers, inputs.size(0), self.hidden_size))\n",
    "        return hidden.cuda() if USE_CUDA else hidden\n",
    "    \n",
    "    def init_weight(self):\n",
    "        self.embedding.weight = nn.init.xavier_uniform(self.embedding.weight)\n",
    "        self.gru.weight_hh_l0 = nn.init.xavier_uniform(self.gru.weight_hh_l0)\n",
    "        self.gru.weight_ih_l0 = nn.init.xavier_uniform(self.gru.weight_ih_l0)\n",
    "        self.linear.weight = nn.init.xavier_uniform(self.linear.weight)\n",
    "        self.attn.weight = nn.init.xavier_uniform(self.attn.weight)\n",
    "\n",
    "    def Attention(self, hidden, encoder_outputs, encoder_maskings):\n",
    "        \"\"\"\n",
    "        hidden : 1,B,D\n",
    "        encoder_outputs : B,T,D\n",
    "        encoder_maskings : B,T # ByteTensor\n",
    "        \"\"\"\n",
    "        # hidden 차원 변경\n",
    "        hidden = hidden[0].unsqueeze(2) # (1,B,D) -> (B,D,1)\n",
    "\n",
    "        # encoder_output의 크기 가져옴\n",
    "        batch_size = encoder_outputs.size(0) # B\n",
    "        max_len = encoder_outputs.size(1) # T\n",
    "        # attention 에너지 계산\n",
    "        energies = self.attn(encoder_outputs.contiguous().view(batch_size * max_len, -1)) # B,T,D -> B*T,D -> B*T,1 \n",
    "        energies = energies.view(batch_size, max_len, -1) # B,T,D\n",
    "        attn_energies = energies.bmm(hidden).squeeze(2) # B,T,D * B,D,1 -> B,T\n",
    "\n",
    "        # 소프트맥스를 통해 attention distribution 계산\n",
    "        alpha = F.softmax(attn_energies, 1) # B,T\n",
    "        alpha = alpha.unsqueeze(1) # B,1,T\n",
    "        # context vector 계산\n",
    "        context = alpha.bmm(encoder_outputs) # B,1,T * B,T,D -> B,1,D\n",
    "\n",
    "        return context, alpha\n",
    "    \n",
    "    def forward(self, inputs, context, max_length, encoder_outputs, encoder_maskings=None, is_training=False):\n",
    "        \"\"\"\n",
    "        inputs : B,1 (전 단계 출력)\n",
    "        context : B,1,D (encoder 출력값)\n",
    "        max_length : int decoding 최대 길이\n",
    "        encoder_outputs : B,T,D\n",
    "        encoder_maskings : B,T # ByteTensor\n",
    "        is_training : bool, 드롭아웃을 training 때만 적용\n",
    "        \"\"\"\n",
    "        # 입력 단어의 임베딩 계산\n",
    "        embedded = self.embedding(inputs)\n",
    "        # hidden state 초기화\n",
    "        hidden = self.init_hidden(inputs)\n",
    "        # training 때만 드롭아웃 적용\n",
    "        if is_training:\n",
    "            embedded = self.dropout(embedded)\n",
    "\n",
    "        decode = []\n",
    "        # GRU 적용\n",
    "        for i in range(max_length):\n",
    "            # GRU의 입력으로 embedded와 context를 연결하여 사용\n",
    "            _, hidden = self.gru(torch.cat((embedded, context), 2), hidden) # h_t = f(h_{t-1}, y_{t-1}, c)\n",
    "            # hidden과 context를 연겨하여 concated를 생성\n",
    "            concated = torch.cat((hidden, context.transpose(0, 1)), 2) # y_t = g(h_t,y_{t-1},c)\n",
    "            # 선형 레이어를 통해 score를 계산\n",
    "            score = self.linear(concated.squeeze(0))\n",
    "            # score에 softmax를 적용하여 확률값 계산\n",
    "            softmaxed = F.log_softmax(score)\n",
    "            # softmax 결과를 decode에 추가\n",
    "            decode.append(softmaxed)\n",
    "            # softmaxed 최대값 인덱스를 decode에 저장\n",
    "            decoded = softmaxed.max(1)[1]\n",
    "            # decoded를 임베딩ㅎ하여 embedded를 업데이트\n",
    "            embedded = self.embedding(decoded).unsqueeze(1) # y_{t-1}\n",
    "            # 훈련 단계에서만 드롭아웃 적용\n",
    "            if is_training:\n",
    "                embedded = self.dropout(embedded)\n",
    "            \n",
    "            # attention을 사용하여 다음 context 벡터 계산\n",
    "            context, alpha = self.Attention(hidden, encoder_outputs, encoder_maskings)\n",
    "\n",
    "        # decode의 결과를 하나의 텐서로 만들어 반환\n",
    "        scores = torch.cat(decode, 1)\n",
    "        # scores 크기 변경\n",
    "        return scores.view(inputs.size(0) * max_length, -1)\n",
    "    \n",
    "    # 디코딩 함수\n",
    "    def decode(self, context, encoder_outputs):\n",
    "        # 디코딩을 시작하는 심볼을 start_decode에 저장\n",
    "        start_decode = Variable(LongTensor([[target2index['<s>']] * 1])).transpose(0, 1)\n",
    "        # start_decode를 임베딩\n",
    "        embedded = self.embedding(start_decode)\n",
    "        # hidden state 초기화\n",
    "        hidden = self.init_hidden(start_decode)\n",
    "\n",
    "        decodes = []\n",
    "        attentions = []\n",
    "        decoded = embedded\n",
    "        # decoded가 종료 심볼이 될 때까지 반복\n",
    "        while decoded.data.tolist()[0] != target2index['</s>']: # </s>가 나올 때까지\n",
    "            # GRU의 입력으로 embedded와 context를 연결하여 사용\n",
    "            _, hidden = self.gru(torch.cat((embedded, context), 2), hidden)\n",
    "            # hidden과 context를 연결하여 concated를 생성\n",
    "            concated = torch.cat((hidden, context.transpose(0, 1)), 2)\n",
    "            # 선형 레이어를 통해 score를 계산\n",
    "            score = self.linear(concated.squeeze(0))\n",
    "            # score에 softmax를 적용하여 확률값 계산\n",
    "            softmaxed = F.log_softmax(score)\n",
    "            # softmaxed 최대값 인덱스를 decode에 저장\n",
    "            decoded = softmaxed.max(1)[1]\n",
    "            # decoded를 임베딩하여 embedded를 업데이트\n",
    "            embedded = self.embedding(decoded).unsqueeze(1)\n",
    "            # attention을 사용하여 다음 context 벡터 계산\n",
    "            context, alpha = self.Attention(hidden, encoder_outputs, None)\n",
    "            # decoded 결과를 decodes에 추가\n",
    "            decodes.append(decoded)\n",
    "            # attention 결과를 attentions에 추가\n",
    "            attentions.append(alpha)\n",
    "\n",
    "        # decodes와 attentions를 하나의 텐서로 만들어 반환\n",
    "        return torch.cat(decodes).squeeze(), torch.cat(attentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2seq 번역 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00/5] [000/115] mean_loss : 8.91\n",
      "[00/5] [050/115] mean_loss : 5.00\n",
      "[00/5] [100/115] mean_loss : 3.93\n",
      "[01/5] [000/115] mean_loss : 3.68\n",
      "[01/5] [050/115] mean_loss : 3.29\n",
      "[01/5] [100/115] mean_loss : 2.99\n",
      "[02/5] [000/115] mean_loss : 2.60\n",
      "[02/5] [050/115] mean_loss : 2.54\n",
      "[02/5] [100/115] mean_loss : 2.38\n",
      "[03/5] [000/115] mean_loss : 2.22\n",
      "[03/5] [050/115] mean_loss : 2.06\n",
      "[03/5] [100/115] mean_loss : 1.97\n",
      "[04/5] [000/115] mean_loss : 1.83\n",
      "[04/5] [050/115] mean_loss : 1.68\n",
      "[04/5] [100/115] mean_loss : 1.67\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 5\n",
    "BATCH_SIZE =256\n",
    "EMBEDDING_SIZE = 300\n",
    "HIDDEN_SIZE = 512\n",
    "LR = 0.001\n",
    "DECODER_LEARNING_RATIO = 5.0\n",
    "RESCHEDULED = False\n",
    "\n",
    "encoder = Encoder(len(source2index), EMBEDDING_SIZE, HIDDEN_SIZE, 3, True)\n",
    "decoder = Decoder(len(target2index), EMBEDDING_SIZE, HIDDEN_SIZE * 2)\n",
    "\n",
    "encoder.init_weight()\n",
    "decoder.init_weight()\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "enc_optim = optim.Adam(encoder.parameters(), lr=LR)\n",
    "dec_optim = optim.Adam(decoder.parameters(), lr=LR * DECODER_LEARNING_RATIO)\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    losses=[] # 손실을 저장할 리스트\n",
    "    for i, batch in enumerate(getBatch(BATCH_SIZE, train_data)): # 배치 사이즈만큼 데이터를 가져옴\n",
    "        inputs, targets, input_lengths, target_lengths = pad_to_batch(batch, source2index, target2index) # 배치 데이터를 패딩\n",
    "\n",
    "        # 입력 데이터에 대한 마스크 생성\n",
    "        input_masks = torch.cat([Variable(ByteTensor(tuple(map(lambda s: s ==0, t.data)))) for t in inputs]).view(inputs.size(0), -1)\n",
    "        start_decode = Variable(LongTensor([[target2index['<s>']] * targets.size(0)])).transpose(0, 1) # 디코딩 시작 토큰 설정\n",
    "        encoder.zero_grad() # 인코더의 그래디언트 초기화\n",
    "        decoder.zero_grad() # 디코더의 그래디언트 초기화\n",
    "        output, hidden_c = encoder(inputs, input_lengths) # 인코더를 통해 출력과 히든 상태 얻음\n",
    "\n",
    "        # 디코더를 통해 예측값 생성\n",
    "        preds = decoder(start_decode, hidden_c, targets.size(1), output, input_masks, True)\n",
    "\n",
    "        loss = loss_function(preds, targets.view(-1)) # 손실 계산\n",
    "        losses.append(loss.data.tolist() ) # 손실 저장\n",
    "        loss.backward() # 역전파 수행\n",
    "        torch.nn.utils.clip_grad_norm(encoder.parameters(), 50.0) # 그래디언트 클리핑\n",
    "        torch.nn.utils.clip_grad_norm(decoder.parameters(), 50.0) # 그래디언트 클리핑\n",
    "        enc_optim.step() # 인코더 파라미터 업데이트\n",
    "        dec_optim.step() # 디코더 파라미터 업데이트\n",
    "\n",
    "        # 일정 간격으로 손실 출력\n",
    "        if i % 50 == 0 or i % len(train_data) == 0:\n",
    "            print(\"[%02d/%d] [%03d/%d] mean_loss : %0.2f\" %(epoch, EPOCH, i, len(train_data)//BATCH_SIZE, np.mean(losses)))\n",
    "            losses=[]\n",
    "\n",
    "    # 학습 중간에 학습률 재조정\n",
    "    if RESCHEDULED == False and epoch  == EPOCH//2:\n",
    "        LR *= 0.01\n",
    "        enc_optimizer = optim.Adam(encoder.parameters(), lr=LR)\n",
    "        dec_optimizer = optim.Adam(decoder.parameters(), lr=LR * DECODER_LEARNING_RATIO)\n",
    "        RESCHEDULED = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 어텐션 시각화 함수 및 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source :  no one knew that .\n",
      "Truth :  personne ne savait ca .\n",
      "Prediction :  personne ne le cela .\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_attention(input_words, output_words, attentions):\n",
    "    attentions = attentions.squeeze(1)\n",
    "    # 색상 바를 가진 plot 설정\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone') # attention을 나타내는 행렬을 plot으로 표현\n",
    "    fig.colorbar(cax) # 색상 바 추가\n",
    "\n",
    "    # 축 설정\n",
    "    ax.set_xticklabels([''] + input_words, rotation=90) # x축에 입력 단어 설정\n",
    "    ax.set_yticklabels([''] + output_words) # y축에 출력 단어 설정\n",
    "\n",
    "    # 모든 눈금에 레이블 표시\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show() # plot 표시\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "test = random.choice(train_data) # 학습 데이터에서 무작위로 하나 선택\n",
    "input_ = test[0] # 입력 데이터\n",
    "truth = test[1] # 실제 값\n",
    "\n",
    "output, hidden = encoder(input_, [input_.size(1)]) # 인코더를 통해 출력과 히든 상태 얻음\n",
    "pred, attn = decoder.decode(hidden, output) # 디코더를 통해 예측값과 attention 얻음\n",
    "\n",
    "input_ = [index2source[i] for i in input_.data.tolist()[0]] # 입력 데이터를 단어로 변환\n",
    "pred = [index2target[i] for i in pred.data.tolist()] # 예측값을 단어로 변환\n",
    "\n",
    "# 결과 출력\n",
    "print('Source : ',' '.join([i for i in input_ if i not in ['</s>']])) # 입력 문장 출력\n",
    "print('Truth : ',' '.join([index2target[i] for i in truth.data.tolist()[0] if i not in [2, 3]])) # 실제 문장 출력\n",
    "print('Prediction : ',' '.join([i for i in pred if i not in ['</s>']])) # 예측 문장 출력\n",
    "\n",
    "if USE_CUDA:\n",
    "    attn = attn.cpu() # CUDA를 사용하는 경우, attention을 CPU로 이동\n",
    "\n",
    "show_attention(input_, pred, attn.data) # attention을 plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
